{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4phrXcQleuC",
        "outputId": "f4c36396-03dd-4279-85b9-2949471d41dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkjOHhTEllqf",
        "outputId": "fd707a52-491f-4a55-b13c-efd0b78dd7be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FaceAging\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/FaceAging/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zcqTEMKxmLCA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import Input, Model\n",
        "from keras.applications import InceptionResNetV2\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.layers import Conv2D, Flatten, Dense, BatchNormalization, Reshape, concatenate, LeakyReLU, Lambda, Activation, UpSampling2D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras_preprocessing import image\n",
        "from scipy.io import loadmat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Wy3LdTyJmLx1"
      },
      "outputs": [],
      "source": [
        "def build_encoder():\n",
        "    \"\"\"\n",
        "    Encoder Network\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(64, 64, 3))\n",
        "\n",
        "    # 1st Convolutional Block\n",
        "    enc = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(input_layer)\n",
        "    # enc = BatchNormalization()(enc)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # 2nd Convolutional Block\n",
        "    enc = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(enc)\n",
        "    enc = BatchNormalization()(enc)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # 3rd Convolutional Block\n",
        "    enc = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(enc)\n",
        "    enc = BatchNormalization()(enc)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # 4th Convolutional Block\n",
        "    enc = Conv2D(filters=256, kernel_size=5, strides=2, padding='same')(enc)\n",
        "    enc = BatchNormalization()(enc)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # Flatten layer\n",
        "    enc = Flatten()(enc)\n",
        "\n",
        "    # 1st Fully Connected Layer\n",
        "    enc = Dense(4096)(enc)\n",
        "    enc = BatchNormalization()(enc)\n",
        "    enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # Second Fully Connected Layer\n",
        "    enc = Dense(100)(enc)\n",
        "\n",
        "    # Create a model\n",
        "    model = Model(inputs=[input_layer], outputs=[enc])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uR5RXJ0Fm2ep"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "    \"\"\"\n",
        "    Create a Generator Model with hyperparameters values defined as follows\n",
        "    \"\"\"\n",
        "    latent_dims = 100\n",
        "    num_classes = 6\n",
        "\n",
        "    input_z_noise = Input(shape=(latent_dims,))\n",
        "    input_label = Input(shape=(num_classes,))\n",
        "\n",
        "    x = concatenate([input_z_noise, input_label])\n",
        "\n",
        "    x = Dense(2048, input_dim=latent_dims + num_classes)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(256 * 8 * 8)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Reshape((8, 8, 256))(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(filters=128, kernel_size=5, padding='same')(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(filters=64, kernel_size=5, padding='same')(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(filters=3, kernel_size=5, padding='same')(x)\n",
        "    x = Activation('tanh')(x)\n",
        "\n",
        "    model = Model(inputs=[input_z_noise, input_label], outputs=[x])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tFQGyewZm3Ro"
      },
      "outputs": [],
      "source": [
        "def expand_label_input(x):\n",
        "    x = K.expand_dims(x, axis=1)\n",
        "    x = K.expand_dims(x, axis=1)\n",
        "    x = K.tile(x, [1, 32, 32, 1])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wOy_JtPMm7rU"
      },
      "outputs": [],
      "source": [
        "def build_discriminator():\n",
        "    \"\"\"\n",
        "    Create a Discriminator Model with hyperparameters values defined as follows\n",
        "    \"\"\"\n",
        "    input_shape = (64, 64, 3)\n",
        "    label_shape = (6,)\n",
        "    image_input = Input(shape=input_shape)\n",
        "    label_input = Input(shape=label_shape)\n",
        "\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding='same')(image_input)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    label_input1 = Lambda(expand_label_input)(label_input)\n",
        "    x = concatenate([x, label_input1], axis=3)\n",
        "\n",
        "    x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(512, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=[image_input, label_input], outputs=[x])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MlZ0x2tbm_xn"
      },
      "outputs": [],
      "source": [
        "def build_fr_combined_network(encoder, generator, fr_model):\n",
        "    input_image = Input(shape=(64, 64, 3))\n",
        "    input_label = Input(shape=(6,))\n",
        "\n",
        "    latent0 = encoder(input_image)\n",
        "\n",
        "    gen_images = generator([latent0, input_label])\n",
        "\n",
        "    fr_model.trainable = False\n",
        "\n",
        "    resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor=2, width_factor=2,\n",
        "                                                      data_format='channels_last'))(gen_images)\n",
        "    embeddings = fr_model(resized_images)\n",
        "\n",
        "    model = Model(inputs=[input_image, input_label], outputs=[embeddings])\n",
        "    return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dzKn4NEDnEtz"
      },
      "outputs": [],
      "source": [
        "def build_fr_model(input_shape):\n",
        "    resent_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
        "    image_input = resent_model.input\n",
        "    x = resent_model.layers[-1].output\n",
        "    out = Dense(128)(x)\n",
        "    embedder_model = Model(inputs=[image_input], outputs=[out])\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    x = embedder_model(input_layer)\n",
        "    output = Lambda(lambda x: K.l2_normalize(x, axis=-1))(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[output])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "J5VU7duNnJmJ"
      },
      "outputs": [],
      "source": [
        "def build_image_resizer():\n",
        "    input_layer = Input(shape=(64, 64, 3))\n",
        "\n",
        "    resized_images = Lambda(lambda x: K.resize_images(x, height_factor=3, width_factor=3,\n",
        "                                                      data_format='channels_last'))(input_layer)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[resized_images])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NQua0qR7nQFc"
      },
      "outputs": [],
      "source": [
        "def calculate_age(taken, dob):\n",
        "    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
        "\n",
        "    if birth.month < 7:\n",
        "        return taken - birth.year\n",
        "    else:\n",
        "        return taken - birth.year - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Wn_H1hBcnU9p"
      },
      "outputs": [],
      "source": [
        "def load_data(wiki_dir, dataset='wiki'):\n",
        "    # Load the wiki.mat file\n",
        "    meta = loadmat(os.path.join(wiki_dir, \"{}.mat\".format(dataset)))\n",
        "\n",
        "    # Load the list of all files\n",
        "    full_path = meta[dataset][0, 0][\"full_path\"][0]\n",
        "\n",
        "    # List of Matlab serial date numbers\n",
        "    dob = meta[dataset][0, 0][\"dob\"][0]\n",
        "\n",
        "    # List of years when photo was taken\n",
        "    photo_taken = meta[dataset][0, 0][\"photo_taken\"][0]  # year\n",
        "\n",
        "    # Calculate age for all dobs\n",
        "    age = [calculate_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
        "\n",
        "    # Create a list of tuples containing a pair of an image path and age\n",
        "    images = []\n",
        "    age_list = []\n",
        "    for index, image_path in enumerate(full_path):\n",
        "        images.append(image_path[0])\n",
        "        age_list.append(age[index])\n",
        "\n",
        "    # Return a list of all images and respective age\n",
        "    return images, age_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8dAWBRRInmG7"
      },
      "outputs": [],
      "source": [
        "def age_to_category(age_list):\n",
        "    age_list1 = []\n",
        "\n",
        "    for age in age_list:\n",
        "        if 0 < age <= 18:\n",
        "            age_category = 0\n",
        "        elif 18 < age <= 29:\n",
        "            age_category = 1\n",
        "        elif 29 < age <= 39:\n",
        "            age_category = 2\n",
        "        elif 39 < age <= 49:\n",
        "            age_category = 3\n",
        "        elif 49 < age <= 59:\n",
        "            age_category = 4\n",
        "        elif age >= 60:\n",
        "            age_category = 5\n",
        "\n",
        "        age_list1.append(age_category)\n",
        "\n",
        "    return age_list1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Rel01Xffnqw4"
      },
      "outputs": [],
      "source": [
        "def load_images(data_dir, image_paths, image_shape):\n",
        "    images = None\n",
        "\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        print()\n",
        "        try:\n",
        "            # Load image\n",
        "            loaded_image = image.load_img(os.path.join(data_dir, image_path), target_size=image_shape)\n",
        "\n",
        "            # Convert PIL image to numpy ndarray\n",
        "            loaded_image = image.img_to_array(loaded_image)\n",
        "\n",
        "            # Add another dimension (Add batch dimension)\n",
        "            loaded_image = np.expand_dims(loaded_image, axis=0)\n",
        "\n",
        "            # Concatenate all images into one tensor\n",
        "            if images is None:\n",
        "                images = loaded_image\n",
        "            else:\n",
        "                images = np.concatenate([images, loaded_image], axis=0)\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", i, e)\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QZcBIhRCnxkz"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance_loss(y_true, y_pred):\n",
        "    \n",
        "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QE2mmifEn3TL"
      },
      "outputs": [],
      "source": [
        "def write_log(callback, name, value, batch_no):\n",
        "    summary = tf.Summary()\n",
        "    summary_value = summary.value.add()\n",
        "    summary_value.simple_value = value\n",
        "    summary_value.tag = name\n",
        "    callback.writer.add_summary(summary, batch_no)\n",
        "    callback.writer.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "r9OxD8LTn6YA"
      },
      "outputs": [],
      "source": [
        "def save_rgb_img(img, path):\n",
        "    \"\"\"\n",
        "    Save an rgb image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Image\")\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "BbDEO4KSn-Ii",
        "outputId": "ca6f9900-7439-4a84-96ec-76b83686eb0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/FaceAging/wiki_crop/wiki.mat'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2b1aa4abaecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mLoad\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwiki_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wiki\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mage_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mage_to_category\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mfinal_age_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-49c6bc3692b2>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(wiki_dir, dataset)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wiki'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load the wiki.mat file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}.mat\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Load the list of all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/FaceAging/wiki_crop/wiki.mat'"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    data_dir = \"/content/drive/MyDrive/FaceAging/\"\n",
        "    wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
        "    epochs = 500\n",
        "    batch_size = 2\n",
        "    image_shape = (64, 64, 3)\n",
        "    z_shape = 100\n",
        "    TRAIN_GAN = True\n",
        "    TRAIN_ENCODER = False\n",
        "    TRAIN_GAN_WITH_FR = False\n",
        "    fr_image_shape = (192, 192, 3)\n",
        "\n",
        "    # Define optimizers\n",
        "    dis_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "    gen_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "    adversarial_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "\n",
        "    \"\"\"\n",
        "    Build and compile networks\n",
        "    \"\"\"\n",
        "    # Build and compile the discriminator network\n",
        "    discriminator = build_discriminator()\n",
        "    discriminator.compile(loss=['binary_crossentropy'], optimizer=dis_optimizer)\n",
        "\n",
        "    # Build and compile the generator network\n",
        "    generator = build_generator()\n",
        "    generator.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n",
        "\n",
        "    # Build and compile the adversarial model\n",
        "    discriminator.trainable = False\n",
        "    input_z_noise = Input(shape=(100,))\n",
        "    input_label = Input(shape=(6,))\n",
        "    recons_images = generator([input_z_noise, input_label])\n",
        "    valid = discriminator([recons_images, input_label])\n",
        "    adversarial_model = Model(inputs=[input_z_noise, input_label], outputs=[valid])\n",
        "    adversarial_model.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time.time()))\n",
        "    tensorboard.set_model(generator)\n",
        "    tensorboard.set_model(discriminator)\n",
        "\n",
        "    \"\"\"\n",
        "    Load the dataset\n",
        "    \"\"\"\n",
        "    images, age_list = load_data(wiki_dir=wiki_dir, dataset=\"wiki\")\n",
        "    age_cat = age_to_category(age_list)\n",
        "    final_age_cat = np.reshape(np.array(age_cat), [len(age_cat), 1])\n",
        "    classes = len(set(age_cat))\n",
        "    y = to_categorical(final_age_cat, num_classes=len(set(age_cat)))\n",
        "\n",
        "    loaded_images = load_images(wiki_dir, images, (image_shape[0], image_shape[1]))\n",
        "\n",
        "    # Implement label smoothing\n",
        "    real_labels = np.ones((batch_size, 1), dtype=np.float32) * 0.9\n",
        "    fake_labels = np.zeros((batch_size, 1), dtype=np.float32) * 0.1\n",
        "\n",
        "    \"\"\"\n",
        "    Train the generator and the discriminator network\n",
        "    \"\"\"\n",
        "    if TRAIN_GAN:\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:{}\".format(epoch))\n",
        "\n",
        "            gen_losses = []\n",
        "            dis_losses = []\n",
        "\n",
        "            number_of_batches = int(len(loaded_images) / batch_size)\n",
        "            print(\"Number of batches:\", number_of_batches)\n",
        "            for index in range(number_of_batches):\n",
        "                print(\"Batch:{}\".format(index + 1))\n",
        "\n",
        "                images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
        "                z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "                \"\"\"\n",
        "                Train the discriminator network\n",
        "                \"\"\"\n",
        "\n",
        "                # Generate fake images\n",
        "                initial_recon_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "\n",
        "                d_loss_real = discriminator.train_on_batch([images_batch, y_batch], real_labels)\n",
        "                d_loss_fake = discriminator.train_on_batch([initial_recon_images, y_batch], fake_labels)\n",
        "\n",
        "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "                print(\"d_loss:{}\".format(d_loss))\n",
        "\n",
        "                \"\"\"\n",
        "                Train the generator network\n",
        "                \"\"\"\n",
        "\n",
        "                z_noise2 = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "                random_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n",
        "                random_labels = to_categorical(random_labels, 6)\n",
        "\n",
        "                g_loss = adversarial_model.train_on_batch([z_noise2, random_labels], [1] * batch_size)\n",
        "\n",
        "                print(\"g_loss:{}\".format(g_loss))\n",
        "\n",
        "                gen_losses.append(g_loss)\n",
        "                dis_losses.append(d_loss)\n",
        "\n",
        "            # Write losses to Tensorboard\n",
        "            write_log(tensorboard, 'g_loss', np.mean(gen_losses), epoch)\n",
        "            write_log(tensorboard, 'd_loss', np.mean(dis_losses), epoch)\n",
        "\n",
        "            \"\"\"\n",
        "            Generate images after every 10th epoch\n",
        "            \"\"\"\n",
        "            if epoch % 10 == 0:\n",
        "                images_batch = loaded_images[0:batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[0:batch_size]\n",
        "                z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "                gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "\n",
        "                for i, img in enumerate(gen_images[:5]):\n",
        "                    save_rgb_img(img, path=\"results/img_{}_{}.png\".format(epoch, i))\n",
        "\n",
        "        # Save networks\n",
        "        try:\n",
        "            generator.save_weights(\"generator.h5\")\n",
        "            discriminator.save_weights(\"discriminator.h5\")\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "\n",
        "    \"\"\"\n",
        "    Train encoder\n",
        "    \"\"\"\n",
        "\n",
        "    if TRAIN_ENCODER:\n",
        "        # Build and compile encoder\n",
        "        encoder = build_encoder()\n",
        "        encoder.compile(loss=euclidean_distance_loss, optimizer='adam')\n",
        "\n",
        "        # Load the generator network's weights\n",
        "        try:\n",
        "            generator.load_weights(\"generator.h5\")\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "\n",
        "        z_i = np.random.normal(0, 1, size=(5000, z_shape))\n",
        "\n",
        "        y = np.random.randint(low=0, high=6, size=(5000,), dtype=np.int64)\n",
        "        num_classes = len(set(y))\n",
        "        y = np.reshape(np.array(y), [len(y), 1])\n",
        "        y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "\n",
        "            encoder_losses = []\n",
        "\n",
        "            number_of_batches = int(z_i.shape[0] / batch_size)\n",
        "            print(\"Number of batches:\", number_of_batches)\n",
        "            for index in range(number_of_batches):\n",
        "                print(\"Batch:\", index + 1)\n",
        "\n",
        "                z_batch = z_i[index * batch_size:(index + 1) * batch_size]\n",
        "                y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "                generated_images = generator.predict_on_batch([z_batch, y_batch])\n",
        "\n",
        "                # Train the encoder model\n",
        "                encoder_loss = encoder.train_on_batch(generated_images, z_batch)\n",
        "                print(\"Encoder loss:\", encoder_loss)\n",
        "\n",
        "                encoder_losses.append(encoder_loss)\n",
        "\n",
        "            # Write the encoder loss to Tensorboard\n",
        "            write_log(tensorboard, \"encoder_loss\", np.mean(encoder_losses), epoch)\n",
        "\n",
        "        # Save the encoder model\n",
        "        encoder.save_weights(\"encoder.h5\")\n",
        "\n",
        "    \"\"\"\n",
        "    Optimize the encoder and the generator network\n",
        "    \"\"\"\n",
        "    if TRAIN_GAN_WITH_FR:\n",
        "\n",
        "        # Load the encoder network\n",
        "        encoder = build_encoder()\n",
        "        encoder.load_weights(\"encoder.h5\")\n",
        "\n",
        "        # Load the generator network\n",
        "        generator.load_weights(\"generator.h5\")\n",
        "\n",
        "        image_resizer = build_image_resizer()\n",
        "        image_resizer.compile(loss=['binary_crossentropy'], optimizer='adam')\n",
        "\n",
        "        # Face recognition model\n",
        "        fr_model = build_fr_model(input_shape=fr_image_shape)\n",
        "        fr_model.compile(loss=['binary_crossentropy'], optimizer=\"adam\")\n",
        "\n",
        "        # Make the face recognition network as non-trainable\n",
        "        fr_model.trainable = False\n",
        "\n",
        "        # Input layers\n",
        "        input_image = Input(shape=(64, 64, 3))\n",
        "        input_label = Input(shape=(6,))\n",
        "\n",
        "        # Use the encoder and the generator network\n",
        "        latent0 = encoder(input_image)\n",
        "        gen_images = generator([latent0, input_label])\n",
        "\n",
        "        # Resize images to the desired shape\n",
        "        resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor=3, width_factor=3,\n",
        "                                                          data_format='channels_last'))(gen_images)\n",
        "        embeddings = fr_model(resized_images)\n",
        "\n",
        "        # Create a Keras model and specify the inputs and outputs for the network\n",
        "        fr_adversarial_model = Model(inputs=[input_image, input_label], outputs=[embeddings])\n",
        "\n",
        "        # Compile the model\n",
        "        fr_adversarial_model.compile(loss=euclidean_distance_loss, optimizer=adversarial_optimizer)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "\n",
        "            reconstruction_losses = []\n",
        "\n",
        "            number_of_batches = int(len(loaded_images) / batch_size)\n",
        "            print(\"Number of batches:\", number_of_batches)\n",
        "            for index in range(number_of_batches):\n",
        "                print(\"Batch:\", index + 1)\n",
        "\n",
        "                images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "                images_batch_resized = image_resizer.predict_on_batch(images_batch)\n",
        "\n",
        "                real_embeddings = fr_model.predict_on_batch(images_batch_resized)\n",
        "\n",
        "                reconstruction_loss = fr_adversarial_model.train_on_batch([images_batch, y_batch], real_embeddings)\n",
        "\n",
        "                print(\"Reconstruction loss:\", reconstruction_loss)\n",
        "\n",
        "                reconstruction_losses.append(reconstruction_loss)\n",
        "\n",
        "            # Write the reconstruction loss to Tensorboard\n",
        "            write_log(tensorboard, \"reconstruction_loss\", np.mean(reconstruction_losses), epoch)\n",
        "\n",
        "            \"\"\"\n",
        "            Generate images\n",
        "            \"\"\"\n",
        "            if epoch % 10 == 0:\n",
        "                images_batch = loaded_images[0:batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[0:batch_size]\n",
        "                z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "                gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "\n",
        "                for i, img in enumerate(gen_images[:5]):\n",
        "                    save_rgb_img(img, path=\"results/img_opt_{}_{}.png\".format(epoch, i))\n",
        "\n",
        "        # Save improved weights for both of the networks\n",
        "        generator.save_weights(\"generator_optimized.h5\")\n",
        "        encoder.save_weights(\"encoder_optimized.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
